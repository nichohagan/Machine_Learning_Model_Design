{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6935d5d2",
   "metadata": {},
   "source": [
    "## **Building Digital Twin for DWM Using Decision Tree and Random Forest Algorithms**\n",
    "\n",
    "by Nicholas Hagan (nkhagan@ualr.edu)\n",
    "\n",
    "Goal: Predict the performance of the Data Washing Machine using the sample characteristics. Note: All machine parameters are dropped. \n",
    "\n",
    "Target variables: Precision, Recall, F-Measure (call one at a time)\n",
    "\n",
    "Predictive variables: Unique Ratio, Numberic Ratio, Min freq, Max freq, Ave freq, Stdev freq, Min lenght, Max lenght, Ave lenght, Stdev lenght, Min freq Std token, Min lenght Std token, Max freq Error token, Max Blck token len\n",
    "\n",
    "The algorithm is tested on each sample, quality groups, and mixed. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e479ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Installing and importing libraries\n",
    "\n",
    "#!pip install scikit-plot\n",
    "import os\n",
    "import io \n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "from pandas import DataFrame as df\n",
    "import numpy as np\n",
    "#import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.metrics\n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "import math\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b30f59c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAMPLE</th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F-MEAS</th>\n",
       "      <th>LINKEDPAIRS</th>\n",
       "      <th>EXPECTEDPAIRS</th>\n",
       "      <th>TRUEPAIRS</th>\n",
       "      <th>TOKENIZERTYPE</th>\n",
       "      <th>NBR_REFS</th>\n",
       "      <th>TOTAL_TOKENS</th>\n",
       "      <th>...</th>\n",
       "      <th>REMOVE_DUPLICATE_TOKENS</th>\n",
       "      <th>REMOVE_EXCLUDED_BLK_TOKENS</th>\n",
       "      <th>EPSILON</th>\n",
       "      <th>EPSILON_ITERATE</th>\n",
       "      <th>MU</th>\n",
       "      <th>MU_ITERATE</th>\n",
       "      <th>COMPARATOR</th>\n",
       "      <th>MATRIX_NUM_TOKEN_RULE</th>\n",
       "      <th>MATRIX_INITIAL_RULE</th>\n",
       "      <th>BLOCKCORRECTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1G.txt</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>Compress</td>\n",
       "      <td>50</td>\n",
       "      <td>543</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.05</td>\n",
       "      <td>ScoringMatrixKris</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S1G.txt</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>Compress</td>\n",
       "      <td>50</td>\n",
       "      <td>543</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.05</td>\n",
       "      <td>ScoringMatrixKris</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S1G.txt</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>Compress</td>\n",
       "      <td>50</td>\n",
       "      <td>543</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.05</td>\n",
       "      <td>ScoringMatrixKris</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S1G.txt</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>Compress</td>\n",
       "      <td>50</td>\n",
       "      <td>543</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.05</td>\n",
       "      <td>ScoringMatrixKris</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S1G.txt</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>Compress</td>\n",
       "      <td>50</td>\n",
       "      <td>543</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.05</td>\n",
       "      <td>ScoringMatrixKris</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6121</th>\n",
       "      <td>join1.txt</td>\n",
       "      <td>0.6788</td>\n",
       "      <td>0.2024</td>\n",
       "      <td>0.3118</td>\n",
       "      <td>37844</td>\n",
       "      <td>126914</td>\n",
       "      <td>25690</td>\n",
       "      <td>Splitter</td>\n",
       "      <td>24417</td>\n",
       "      <td>546726</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.05</td>\n",
       "      <td>ScoringMatrixKris</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6122</th>\n",
       "      <td>join1.txt</td>\n",
       "      <td>0.6788</td>\n",
       "      <td>0.2024</td>\n",
       "      <td>0.3118</td>\n",
       "      <td>37844</td>\n",
       "      <td>126914</td>\n",
       "      <td>25690</td>\n",
       "      <td>Splitter</td>\n",
       "      <td>24417</td>\n",
       "      <td>546726</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.05</td>\n",
       "      <td>ScoringMatrixKris</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6123</th>\n",
       "      <td>join1.txt</td>\n",
       "      <td>0.6749</td>\n",
       "      <td>0.2024</td>\n",
       "      <td>0.3114</td>\n",
       "      <td>38068</td>\n",
       "      <td>126914</td>\n",
       "      <td>25692</td>\n",
       "      <td>Splitter</td>\n",
       "      <td>24417</td>\n",
       "      <td>546894</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.05</td>\n",
       "      <td>ScoringMatrixKris</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6124</th>\n",
       "      <td>join1.txt</td>\n",
       "      <td>0.6757</td>\n",
       "      <td>0.2029</td>\n",
       "      <td>0.3121</td>\n",
       "      <td>38105</td>\n",
       "      <td>126914</td>\n",
       "      <td>25747</td>\n",
       "      <td>Splitter</td>\n",
       "      <td>24417</td>\n",
       "      <td>547252</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.05</td>\n",
       "      <td>ScoringMatrixKris</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6125</th>\n",
       "      <td>join1.txt</td>\n",
       "      <td>0.6758</td>\n",
       "      <td>0.2028</td>\n",
       "      <td>0.3120</td>\n",
       "      <td>38091</td>\n",
       "      <td>126914</td>\n",
       "      <td>25743</td>\n",
       "      <td>Splitter</td>\n",
       "      <td>24417</td>\n",
       "      <td>547940</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.05</td>\n",
       "      <td>ScoringMatrixKris</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6126 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SAMPLE  PRECISION  RECALL  F-MEAS  LINKEDPAIRS  EXPECTEDPAIRS  \\\n",
       "0       S1G.txt     1.0000  1.0000  1.0000           27             27   \n",
       "1       S1G.txt     1.0000  1.0000  1.0000           27             27   \n",
       "2       S1G.txt     1.0000  1.0000  1.0000           27             27   \n",
       "3       S1G.txt     1.0000  1.0000  1.0000           27             27   \n",
       "4       S1G.txt     1.0000  1.0000  1.0000           27             27   \n",
       "...         ...        ...     ...     ...          ...            ...   \n",
       "6121  join1.txt     0.6788  0.2024  0.3118        37844         126914   \n",
       "6122  join1.txt     0.6788  0.2024  0.3118        37844         126914   \n",
       "6123  join1.txt     0.6749  0.2024  0.3114        38068         126914   \n",
       "6124  join1.txt     0.6757  0.2029  0.3121        38105         126914   \n",
       "6125  join1.txt     0.6758  0.2028  0.3120        38091         126914   \n",
       "\n",
       "      TRUEPAIRS TOKENIZERTYPE  NBR_REFS  TOTAL_TOKENS  ...  \\\n",
       "0            27      Compress        50           543  ...   \n",
       "1            27      Compress        50           543  ...   \n",
       "2            27      Compress        50           543  ...   \n",
       "3            27      Compress        50           543  ...   \n",
       "4            27      Compress        50           543  ...   \n",
       "...         ...           ...       ...           ...  ...   \n",
       "6121      25690      Splitter     24417        546726  ...   \n",
       "6122      25690      Splitter     24417        546726  ...   \n",
       "6123      25692      Splitter     24417        546894  ...   \n",
       "6124      25747      Splitter     24417        547252  ...   \n",
       "6125      25743      Splitter     24417        547940  ...   \n",
       "\n",
       "      REMOVE_DUPLICATE_TOKENS  REMOVE_EXCLUDED_BLK_TOKENS  EPSILON  \\\n",
       "0                        True                        True    0.500   \n",
       "1                        True                        True    0.004   \n",
       "2                        True                        True    0.500   \n",
       "3                        True                        True    0.004   \n",
       "4                        True                        True    0.475   \n",
       "...                       ...                         ...      ...   \n",
       "6121                     True                        True    0.700   \n",
       "6122                     True                        True    0.700   \n",
       "6123                     True                        True    0.700   \n",
       "6124                     True                        True    0.700   \n",
       "6125                     True                        True    0.700   \n",
       "\n",
       "      EPSILON_ITERATE    MU  MU_ITERATE         COMPARATOR  \\\n",
       "0               0.000  0.60        0.05  ScoringMatrixKris   \n",
       "1               0.001  0.60        0.05  ScoringMatrixKris   \n",
       "2               0.000  0.60        0.05  ScoringMatrixKris   \n",
       "3               0.001  0.60        0.05  ScoringMatrixKris   \n",
       "4               0.000  0.60        0.05  ScoringMatrixKris   \n",
       "...               ...   ...         ...                ...   \n",
       "6121            0.000  0.79        0.05  ScoringMatrixKris   \n",
       "6122            0.000  0.79        0.05  ScoringMatrixKris   \n",
       "6123            0.000  0.79        0.05  ScoringMatrixKris   \n",
       "6124            0.000  0.79        0.05  ScoringMatrixKris   \n",
       "6125            0.000  0.79        0.05  ScoringMatrixKris   \n",
       "\n",
       "      MATRIX_NUM_TOKEN_RULE  MATRIX_INITIAL_RULE  BLOCKCORRECTION  \n",
       "0                      True                 True            False  \n",
       "1                      True                 True            False  \n",
       "2                      True                 True            False  \n",
       "3                      True                 True            False  \n",
       "4                      True                 True            False  \n",
       "...                     ...                  ...              ...  \n",
       "6121                   True                 True             True  \n",
       "6122                   True                 True             True  \n",
       "6123                   True                 True             True  \n",
       "6124                   True                 True             True  \n",
       "6125                   True                 True             True  \n",
       "\n",
       "[6126 rows x 41 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing the dataset\n",
    "data = pd.read_csv(\"DWM Sample Test Results.csv\", sep = \",\")  \n",
    "dfd = pd.DataFrame(data)\n",
    "dfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93856de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicho\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='RECALL', ylabel='Density'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visually exploring the dataset \n",
    "sb.distplot(dfd['RECALL'])       #histogram for precision values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf87fae7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAMPLE</th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>UNIQUE_RATIO</th>\n",
       "      <th>NUMERIC_RATIO</th>\n",
       "      <th>MIN_FREQ</th>\n",
       "      <th>MAX_FREQ</th>\n",
       "      <th>AVG_FREQ</th>\n",
       "      <th>STDEV_FREQ</th>\n",
       "      <th>MIN_LEN</th>\n",
       "      <th>MAX_LEN</th>\n",
       "      <th>AVG_LEN</th>\n",
       "      <th>STDEV_LEN</th>\n",
       "      <th>MIN_FREQ_STD_TOKEN</th>\n",
       "      <th>MIN_LEN_STD_TOKEN</th>\n",
       "      <th>MAX_FREQ_ERR_TOKEN</th>\n",
       "      <th>MIN_BLK_TOKEN_LEN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>S10PX.txt</td>\n",
       "      <td>0.7179</td>\n",
       "      <td>0.2360</td>\n",
       "      <td>0.2360</td>\n",
       "      <td>1</td>\n",
       "      <td>722</td>\n",
       "      <td>4.2372</td>\n",
       "      <td>16.7776</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>4.9253</td>\n",
       "      <td>2.5839</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>S10PX.txt</td>\n",
       "      <td>0.7179</td>\n",
       "      <td>0.2360</td>\n",
       "      <td>0.2360</td>\n",
       "      <td>1</td>\n",
       "      <td>722</td>\n",
       "      <td>4.2372</td>\n",
       "      <td>16.7776</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>4.9253</td>\n",
       "      <td>2.5839</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>S10PX.txt</td>\n",
       "      <td>0.7179</td>\n",
       "      <td>0.2360</td>\n",
       "      <td>0.2360</td>\n",
       "      <td>1</td>\n",
       "      <td>722</td>\n",
       "      <td>4.2372</td>\n",
       "      <td>16.7776</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>4.9253</td>\n",
       "      <td>2.5839</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>S10PX.txt</td>\n",
       "      <td>0.7179</td>\n",
       "      <td>0.2360</td>\n",
       "      <td>0.2360</td>\n",
       "      <td>1</td>\n",
       "      <td>722</td>\n",
       "      <td>4.2372</td>\n",
       "      <td>16.7776</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>4.9253</td>\n",
       "      <td>2.5839</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>S10PX.txt</td>\n",
       "      <td>0.7179</td>\n",
       "      <td>0.2360</td>\n",
       "      <td>0.2360</td>\n",
       "      <td>1</td>\n",
       "      <td>722</td>\n",
       "      <td>4.2372</td>\n",
       "      <td>16.7776</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>4.9253</td>\n",
       "      <td>2.5839</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984</th>\n",
       "      <td>S17PX.txt</td>\n",
       "      <td>0.7700</td>\n",
       "      <td>0.1474</td>\n",
       "      <td>0.1474</td>\n",
       "      <td>1</td>\n",
       "      <td>1362</td>\n",
       "      <td>6.7832</td>\n",
       "      <td>30.0717</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>4.4286</td>\n",
       "      <td>2.2330</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5985</th>\n",
       "      <td>S17PX.txt</td>\n",
       "      <td>0.8217</td>\n",
       "      <td>0.1474</td>\n",
       "      <td>0.1474</td>\n",
       "      <td>1</td>\n",
       "      <td>1362</td>\n",
       "      <td>6.7832</td>\n",
       "      <td>30.0717</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>4.4286</td>\n",
       "      <td>2.2330</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5986</th>\n",
       "      <td>S17PX.txt</td>\n",
       "      <td>0.9012</td>\n",
       "      <td>0.1474</td>\n",
       "      <td>0.1474</td>\n",
       "      <td>1</td>\n",
       "      <td>1362</td>\n",
       "      <td>6.7832</td>\n",
       "      <td>30.0717</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>4.4286</td>\n",
       "      <td>2.2330</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5987</th>\n",
       "      <td>S17PX.txt</td>\n",
       "      <td>0.9147</td>\n",
       "      <td>0.1474</td>\n",
       "      <td>0.1474</td>\n",
       "      <td>1</td>\n",
       "      <td>1362</td>\n",
       "      <td>6.7832</td>\n",
       "      <td>30.0717</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>4.4286</td>\n",
       "      <td>2.2330</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5988</th>\n",
       "      <td>S17PX.txt</td>\n",
       "      <td>0.9021</td>\n",
       "      <td>0.1474</td>\n",
       "      <td>0.1474</td>\n",
       "      <td>1</td>\n",
       "      <td>1362</td>\n",
       "      <td>6.7832</td>\n",
       "      <td>30.0717</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>4.4286</td>\n",
       "      <td>2.2330</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1964 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SAMPLE  PRECISION  UNIQUE_RATIO  NUMERIC_RATIO  MIN_FREQ  MAX_FREQ  \\\n",
       "608   S10PX.txt     0.7179        0.2360         0.2360         1       722   \n",
       "609   S10PX.txt     0.7179        0.2360         0.2360         1       722   \n",
       "610   S10PX.txt     0.7179        0.2360         0.2360         1       722   \n",
       "611   S10PX.txt     0.7179        0.2360         0.2360         1       722   \n",
       "612   S10PX.txt     0.7179        0.2360         0.2360         1       722   \n",
       "...         ...        ...           ...            ...       ...       ...   \n",
       "5984  S17PX.txt     0.7700        0.1474         0.1474         1      1362   \n",
       "5985  S17PX.txt     0.8217        0.1474         0.1474         1      1362   \n",
       "5986  S17PX.txt     0.9012        0.1474         0.1474         1      1362   \n",
       "5987  S17PX.txt     0.9147        0.1474         0.1474         1      1362   \n",
       "5988  S17PX.txt     0.9021        0.1474         0.1474         1      1362   \n",
       "\n",
       "      AVG_FREQ  STDEV_FREQ  MIN_LEN  MAX_LEN  AVG_LEN  STDEV_LEN  \\\n",
       "608     4.2372     16.7776        1       15   4.9253     2.5839   \n",
       "609     4.2372     16.7776        1       15   4.9253     2.5839   \n",
       "610     4.2372     16.7776        1       15   4.9253     2.5839   \n",
       "611     4.2372     16.7776        1       15   4.9253     2.5839   \n",
       "612     4.2372     16.7776        1       15   4.9253     2.5839   \n",
       "...        ...         ...      ...      ...      ...        ...   \n",
       "5984    6.7832     30.0717        1       16   4.4286     2.2330   \n",
       "5985    6.7832     30.0717        1       16   4.4286     2.2330   \n",
       "5986    6.7832     30.0717        1       16   4.4286     2.2330   \n",
       "5987    6.7832     30.0717        1       16   4.4286     2.2330   \n",
       "5988    6.7832     30.0717        1       16   4.4286     2.2330   \n",
       "\n",
       "      MIN_FREQ_STD_TOKEN  MIN_LEN_STD_TOKEN  MAX_FREQ_ERR_TOKEN  \\\n",
       "608                    4                  3                   3   \n",
       "609                    4                  3                   3   \n",
       "610                    4                  3                   3   \n",
       "611                    4                  3                   3   \n",
       "612                    4                  3                   3   \n",
       "...                  ...                ...                 ...   \n",
       "5984                   5                  3                   3   \n",
       "5985                   5                  3                   3   \n",
       "5986                   5                  3                   3   \n",
       "5987                   5                  3                   3   \n",
       "5988                   5                  3                   3   \n",
       "\n",
       "      MIN_BLK_TOKEN_LEN  \n",
       "608                   4  \n",
       "609                   4  \n",
       "610                   4  \n",
       "611                   4  \n",
       "612                   4  \n",
       "...                 ...  \n",
       "5984                  4  \n",
       "5985                  4  \n",
       "5986                  4  \n",
       "5987                  4  \n",
       "5988                  4  \n",
       "\n",
       "[1964 rows x 16 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##DROPPING MACHINE PARAMETERS/SETTINGS and THEIR X'TICS;select only sample characteristers\n",
    "\n",
    "dfd.drop(['LINKEDPAIRS', 'EXPECTEDPAIRS', 'TRUEPAIRS','TOTAL_NUMERIC','TOKENIZERTYPE', 'NBR_REFS', 'TOTAL_TOKENS',\n",
    "          'UNIQUE_TOKENS','REMOVE_DUPLICATE_TOKENS','REMOVE_EXCLUDED_BLK_TOKENS','EPSILON','EPSILON_ITERATE','MU','MU_ITERATE',\n",
    "          'BETA','SIGMA','COMPARATOR','MATRIX_NUM_TOKEN_RULE','MATRIX_INITIAL_RULE','BLOCKCORRECTION','BLOCK_BY_PAIRS',\n",
    "            'RUN_GLOBAL_CORRECTION','EXCLUDE_NUMERIC_BLOCKS'],axis=1, inplace = True)\n",
    "\n",
    "\n",
    "##INCLUDE A TARGET VARIABLE TO THE NEW DATA BY DROPPING THE REST \n",
    "dfd.drop(['RECALL','F-MEAS'],axis=1, inplace = True) #Target Variables: PRECISION, RECALL, F-MEAS\n",
    "dfd\n",
    "\n",
    "##EXTRRACTING SAMPLE TYPES TO USE\n",
    "#Data samples: S1G.txt,S2G.txt,S3Rest.txt,S4G.txt,S5G.txt,S6GeCo.txt,S7GX.txt,S8P.txt,S9P.txt,S10PX.txt,S11PX.txt,\n",
    "#S12PX.txt,S13GX.txt,S14GX.txt,S15GX.txt,S16PX.txt,S17PX.txt,S18PX.txt,join1.txt,Pilog.txt,pilog11.txt      \n",
    "\n",
    "#samp = dfd[dfd[\"SAMPLE\"] == 'S18PX.txt']                                                          #individual sample type\n",
    "#samp\n",
    "\n",
    "                      ##select multiple sample types using the 'or' '|' operator##\n",
    "#samp = dfd[(dfd[\"SAMPLE\"] == 'S1G.txt')|(dfd[\"SAMPLE\"] == 'S2G.txt')|(dfd[\"SAMPLE\"] == 'S4G.txt')|\n",
    "#         (dfd[\"SAMPLE\"] == 'S5G.txt')|(dfd[\"SAMPLE\"] == 'S7GX.txt')|(dfd[\"SAMPLE\"] == 'S13GX.txt')|\n",
    "#       (dfd[\"SAMPLE\"] == 'S14GX.txt')|(dfd[\"SAMPLE\"] == 'S15GX.txt')]                              #good quality samples only              \n",
    "#samp\n",
    "\n",
    "samp = dfd[(dfd[\"SAMPLE\"] == 'S8P.txt')|(dfd[\"SAMPLE\"] == 'S9P.txt')|(dfd[\"SAMPLE\"] == 'S10PX.txt')|\n",
    "         (dfd[\"SAMPLE\"] == 'S11PX.txt')|(dfd[\"SAMPLE\"] == 'S12PX.txt')|(dfd[\"SAMPLE\"] == 'S16PX.txt')|\n",
    "         (dfd[\"SAMPLE\"] == 'S17PX.txt')|(dfd[\"SAMPLE\"] == 'S8PX.txt')]                             #poor quality samples only              \n",
    "samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9034da6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>UNIQUE_RATIO</th>\n",
       "      <th>NUMERIC_RATIO</th>\n",
       "      <th>MIN_FREQ</th>\n",
       "      <th>MAX_FREQ</th>\n",
       "      <th>AVG_FREQ</th>\n",
       "      <th>STDEV_FREQ</th>\n",
       "      <th>MIN_LEN</th>\n",
       "      <th>MAX_LEN</th>\n",
       "      <th>AVG_LEN</th>\n",
       "      <th>STDEV_LEN</th>\n",
       "      <th>MIN_FREQ_STD_TOKEN</th>\n",
       "      <th>MIN_LEN_STD_TOKEN</th>\n",
       "      <th>MAX_FREQ_ERR_TOKEN</th>\n",
       "      <th>MIN_BLK_TOKEN_LEN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>0.7179</td>\n",
       "      <td>0.2360</td>\n",
       "      <td>0.2360</td>\n",
       "      <td>1</td>\n",
       "      <td>722</td>\n",
       "      <td>4.2372</td>\n",
       "      <td>16.7776</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>4.9253</td>\n",
       "      <td>2.5839</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>0.7179</td>\n",
       "      <td>0.2360</td>\n",
       "      <td>0.2360</td>\n",
       "      <td>1</td>\n",
       "      <td>722</td>\n",
       "      <td>4.2372</td>\n",
       "      <td>16.7776</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>4.9253</td>\n",
       "      <td>2.5839</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>0.7179</td>\n",
       "      <td>0.2360</td>\n",
       "      <td>0.2360</td>\n",
       "      <td>1</td>\n",
       "      <td>722</td>\n",
       "      <td>4.2372</td>\n",
       "      <td>16.7776</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>4.9253</td>\n",
       "      <td>2.5839</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>0.7179</td>\n",
       "      <td>0.2360</td>\n",
       "      <td>0.2360</td>\n",
       "      <td>1</td>\n",
       "      <td>722</td>\n",
       "      <td>4.2372</td>\n",
       "      <td>16.7776</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>4.9253</td>\n",
       "      <td>2.5839</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>0.7179</td>\n",
       "      <td>0.2360</td>\n",
       "      <td>0.2360</td>\n",
       "      <td>1</td>\n",
       "      <td>722</td>\n",
       "      <td>4.2372</td>\n",
       "      <td>16.7776</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>4.9253</td>\n",
       "      <td>2.5839</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984</th>\n",
       "      <td>0.7700</td>\n",
       "      <td>0.1474</td>\n",
       "      <td>0.1474</td>\n",
       "      <td>1</td>\n",
       "      <td>1362</td>\n",
       "      <td>6.7832</td>\n",
       "      <td>30.0717</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>4.4286</td>\n",
       "      <td>2.2330</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5985</th>\n",
       "      <td>0.8217</td>\n",
       "      <td>0.1474</td>\n",
       "      <td>0.1474</td>\n",
       "      <td>1</td>\n",
       "      <td>1362</td>\n",
       "      <td>6.7832</td>\n",
       "      <td>30.0717</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>4.4286</td>\n",
       "      <td>2.2330</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5986</th>\n",
       "      <td>0.9012</td>\n",
       "      <td>0.1474</td>\n",
       "      <td>0.1474</td>\n",
       "      <td>1</td>\n",
       "      <td>1362</td>\n",
       "      <td>6.7832</td>\n",
       "      <td>30.0717</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>4.4286</td>\n",
       "      <td>2.2330</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5987</th>\n",
       "      <td>0.9147</td>\n",
       "      <td>0.1474</td>\n",
       "      <td>0.1474</td>\n",
       "      <td>1</td>\n",
       "      <td>1362</td>\n",
       "      <td>6.7832</td>\n",
       "      <td>30.0717</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>4.4286</td>\n",
       "      <td>2.2330</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5988</th>\n",
       "      <td>0.9021</td>\n",
       "      <td>0.1474</td>\n",
       "      <td>0.1474</td>\n",
       "      <td>1</td>\n",
       "      <td>1362</td>\n",
       "      <td>6.7832</td>\n",
       "      <td>30.0717</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>4.4286</td>\n",
       "      <td>2.2330</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1964 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PRECISION  UNIQUE_RATIO  NUMERIC_RATIO  MIN_FREQ  MAX_FREQ  AVG_FREQ  \\\n",
       "608      0.7179        0.2360         0.2360         1       722    4.2372   \n",
       "609      0.7179        0.2360         0.2360         1       722    4.2372   \n",
       "610      0.7179        0.2360         0.2360         1       722    4.2372   \n",
       "611      0.7179        0.2360         0.2360         1       722    4.2372   \n",
       "612      0.7179        0.2360         0.2360         1       722    4.2372   \n",
       "...         ...           ...            ...       ...       ...       ...   \n",
       "5984     0.7700        0.1474         0.1474         1      1362    6.7832   \n",
       "5985     0.8217        0.1474         0.1474         1      1362    6.7832   \n",
       "5986     0.9012        0.1474         0.1474         1      1362    6.7832   \n",
       "5987     0.9147        0.1474         0.1474         1      1362    6.7832   \n",
       "5988     0.9021        0.1474         0.1474         1      1362    6.7832   \n",
       "\n",
       "      STDEV_FREQ  MIN_LEN  MAX_LEN  AVG_LEN  STDEV_LEN  MIN_FREQ_STD_TOKEN  \\\n",
       "608      16.7776        1       15   4.9253     2.5839                   4   \n",
       "609      16.7776        1       15   4.9253     2.5839                   4   \n",
       "610      16.7776        1       15   4.9253     2.5839                   4   \n",
       "611      16.7776        1       15   4.9253     2.5839                   4   \n",
       "612      16.7776        1       15   4.9253     2.5839                   4   \n",
       "...          ...      ...      ...      ...        ...                 ...   \n",
       "5984     30.0717        1       16   4.4286     2.2330                   5   \n",
       "5985     30.0717        1       16   4.4286     2.2330                   5   \n",
       "5986     30.0717        1       16   4.4286     2.2330                   5   \n",
       "5987     30.0717        1       16   4.4286     2.2330                   5   \n",
       "5988     30.0717        1       16   4.4286     2.2330                   5   \n",
       "\n",
       "      MIN_LEN_STD_TOKEN  MAX_FREQ_ERR_TOKEN  MIN_BLK_TOKEN_LEN  \n",
       "608                   3                   3                  4  \n",
       "609                   3                   3                  4  \n",
       "610                   3                   3                  4  \n",
       "611                   3                   3                  4  \n",
       "612                   3                   3                  4  \n",
       "...                 ...                 ...                ...  \n",
       "5984                  3                   3                  4  \n",
       "5985                  3                   3                  4  \n",
       "5986                  3                   3                  4  \n",
       "5987                  3                   3                  4  \n",
       "5988                  3                   3                  4  \n",
       "\n",
       "[1964 rows x 15 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###COLUMN FILTERING 2 - DROPPING SAMPLE NAME COLUMN\n",
    "pd.set_option('mode.chained_assignment', None)   #Prevents a run-time warning\n",
    "samp.drop('SAMPLE',axis=1, inplace = True)\n",
    "samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bc32147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PRECISION', 'UNIQUE_RATIO', 'NUMERIC_RATIO', 'MIN_FREQ', 'MAX_FREQ',\n",
       "       'AVG_FREQ', 'STDEV_FREQ', 'MIN_LEN', 'MAX_LEN', 'AVG_LEN', 'STDEV_LEN',\n",
       "       'MIN_FREQ_STD_TOKEN', 'MIN_LEN_STD_TOKEN', 'MAX_FREQ_ERR_TOKEN',\n",
       "       'MIN_BLK_TOKEN_LEN'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "867b2ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>UNIQUE_RATIO</th>\n",
       "      <th>NUMERIC_RATIO</th>\n",
       "      <th>MIN_FREQ</th>\n",
       "      <th>MAX_FREQ</th>\n",
       "      <th>AVG_FREQ</th>\n",
       "      <th>STDEV_FREQ</th>\n",
       "      <th>MIN_LEN</th>\n",
       "      <th>MAX_LEN</th>\n",
       "      <th>AVG_LEN</th>\n",
       "      <th>STDEV_LEN</th>\n",
       "      <th>MIN_FREQ_STD_TOKEN</th>\n",
       "      <th>MIN_LEN_STD_TOKEN</th>\n",
       "      <th>MAX_FREQ_ERR_TOKEN</th>\n",
       "      <th>MIN_BLK_TOKEN_LEN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1964.000000</td>\n",
       "      <td>1964.000000</td>\n",
       "      <td>1964.000000</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>1964.000000</td>\n",
       "      <td>1964.000000</td>\n",
       "      <td>1964.000000</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>1964.000000</td>\n",
       "      <td>1964.000000</td>\n",
       "      <td>1964.000000</td>\n",
       "      <td>1964.000000</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>1964.000000</td>\n",
       "      <td>1964.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.433755</td>\n",
       "      <td>0.210731</td>\n",
       "      <td>0.211333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>991.218941</td>\n",
       "      <td>5.017991</td>\n",
       "      <td>20.909671</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.071283</td>\n",
       "      <td>4.481173</td>\n",
       "      <td>2.247178</td>\n",
       "      <td>4.680754</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000509</td>\n",
       "      <td>2.585031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.304946</td>\n",
       "      <td>0.051367</td>\n",
       "      <td>0.052796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>589.149531</td>\n",
       "      <td>1.140735</td>\n",
       "      <td>8.430754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.187821</td>\n",
       "      <td>0.153548</td>\n",
       "      <td>0.110132</td>\n",
       "      <td>0.466303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022565</td>\n",
       "      <td>0.847158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.139000</td>\n",
       "      <td>0.139000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>232.000000</td>\n",
       "      <td>3.041300</td>\n",
       "      <td>9.453700</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>4.298200</td>\n",
       "      <td>2.107800</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.166400</td>\n",
       "      <td>0.166400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>405.000000</td>\n",
       "      <td>3.823700</td>\n",
       "      <td>11.939800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>4.404300</td>\n",
       "      <td>2.207000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.537700</td>\n",
       "      <td>0.194600</td>\n",
       "      <td>0.194600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>790.000000</td>\n",
       "      <td>5.138600</td>\n",
       "      <td>18.706200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>4.429000</td>\n",
       "      <td>2.232800</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.687800</td>\n",
       "      <td>0.261500</td>\n",
       "      <td>0.261500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1538.000000</td>\n",
       "      <td>6.008800</td>\n",
       "      <td>29.409200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>4.537600</td>\n",
       "      <td>2.255800</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.953100</td>\n",
       "      <td>0.328800</td>\n",
       "      <td>0.400500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2011.000000</td>\n",
       "      <td>7.194800</td>\n",
       "      <td>33.728100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>5.175100</td>\n",
       "      <td>2.753400</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PRECISION  UNIQUE_RATIO  NUMERIC_RATIO  MIN_FREQ     MAX_FREQ  \\\n",
       "count  1964.000000   1964.000000    1964.000000    1964.0  1964.000000   \n",
       "mean      0.433755      0.210731       0.211333       1.0   991.218941   \n",
       "std       0.304946      0.051367       0.052796       0.0   589.149531   \n",
       "min       0.001900      0.139000       0.139000       1.0   232.000000   \n",
       "25%       0.006400      0.166400       0.166400       1.0   405.000000   \n",
       "50%       0.537700      0.194600       0.194600       1.0   790.000000   \n",
       "75%       0.687800      0.261500       0.261500       1.0  1538.000000   \n",
       "max       0.953100      0.328800       0.400500       1.0  2011.000000   \n",
       "\n",
       "          AVG_FREQ   STDEV_FREQ  MIN_LEN      MAX_LEN      AVG_LEN  \\\n",
       "count  1964.000000  1964.000000   1964.0  1964.000000  1964.000000   \n",
       "mean      5.017991    20.909671      1.0    16.071283     4.481173   \n",
       "std       1.140735     8.430754      0.0     2.187821     0.153548   \n",
       "min       3.041300     9.453700      1.0    13.000000     4.298200   \n",
       "25%       3.823700    11.939800      1.0    15.000000     4.404300   \n",
       "50%       5.138600    18.706200      1.0    15.000000     4.429000   \n",
       "75%       6.008800    29.409200      1.0    16.000000     4.537600   \n",
       "max       7.194800    33.728100      1.0    21.000000     5.175100   \n",
       "\n",
       "         STDEV_LEN  MIN_FREQ_STD_TOKEN  MIN_LEN_STD_TOKEN  MAX_FREQ_ERR_TOKEN  \\\n",
       "count  1964.000000         1964.000000             1964.0         1964.000000   \n",
       "mean      2.247178            4.680754                3.0            3.000509   \n",
       "std       0.110132            0.466303                0.0            0.022565   \n",
       "min       2.107800            4.000000                3.0            3.000000   \n",
       "25%       2.207000            4.000000                3.0            3.000000   \n",
       "50%       2.232800            5.000000                3.0            3.000000   \n",
       "75%       2.255800            5.000000                3.0            3.000000   \n",
       "max       2.753400            5.000000                3.0            4.000000   \n",
       "\n",
       "       MIN_BLK_TOKEN_LEN  \n",
       "count        1964.000000  \n",
       "mean            2.585031  \n",
       "std             0.847158  \n",
       "min             2.000000  \n",
       "25%             2.000000  \n",
       "50%             2.000000  \n",
       "75%             3.000000  \n",
       "max             4.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4d5209e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(590, 14)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 'P' means predictor variables/dependent variables/determinants\n",
    "## 't' means target variable/independent variable\n",
    "\n",
    "\n",
    "##Defining input and outcome variables\n",
    "X = samp.iloc[:,1:]    #Sample X'tics --depentent variables\n",
    "#X.head(10)\n",
    "y = samp.iloc[:,0]     #Precision  #Recall  #F-Meas  --indepentent variables\n",
    "#y.head(10)\n",
    "\n",
    "##Splitting the dataset\n",
    "#p,t = (samp,samp)      #defining variables for predictors and target\n",
    "#p,t = (depv,indv)\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,y, test_size=0.30, random_state=24) #using same random_state value for replicability\n",
    "###Meaning of data split categories\n",
    "   ##X_train = dep. variables used for training the model\n",
    "   ##Y_train = indep. variables used to training the model together with X-train\n",
    "   ##X_test = dep. variables used for testing the model after training\n",
    "   ##Y_test = indep. variables used for testing the model together with X-test. To be used to comapre predicted values after training\n",
    "#X_train.describe()      #dataset after splitting\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af602dfb",
   "metadata": {},
   "source": [
    "### Decision Tree Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87555a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Calling the decision tree regressor model with default settings and fitting the dataset with model\n",
    "DecTree_reg = DecisionTreeRegressor()                #model without random state gives different result(higher accuracy??)\n",
    "#DecTree_reg = DecisionTreeRegressor(random_state=24) \n",
    "DecTree_reg.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c72706b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77570784 0.52695556 0.88391    0.57412857 0.67593333 0.76663333\n",
      " 0.63409091 0.71287838 0.45482609 0.60154906 0.4517     0.5292\n",
      " 0.6375     0.6775     0.4955     0.16111304 0.6791     0.2756\n",
      " 0.6468     0.16111304 0.71287838 0.67173333 0.70446923 0.12866667\n",
      " 0.6908     0.692875   0.6791     0.00934    0.6908     0.62511429\n",
      " 0.41344    0.39584    0.7372     0.12854    0.1175     0.6674875\n",
      " 0.7508     0.63409091 0.8        0.6468     0.60154906 0.41344\n",
      " 0.101912   0.8364     0.13055714 0.0029     0.08959524 0.6866\n",
      " 0.08605    0.62396667 0.16111304 0.734625   0.60035    0.110225\n",
      " 0.1175     0.52695556 0.13055714 0.32005    0.67173333 0.0032\n",
      " 0.482332   0.71287838 0.64681053 0.692875   0.0717087  0.08605\n",
      " 0.004      0.16111304 0.62396667 0.64681053 0.00205    0.6468\n",
      " 0.6866     0.16111304 0.71287838 0.12854    0.16111304 0.5769\n",
      " 0.0034     0.52460385 0.64681053 0.00855    0.08605    0.002\n",
      " 0.734625   0.4955     0.7027     0.1175     0.0717087  0.5584\n",
      " 0.12854    0.8934     0.6398     0.71287838 0.68535    0.08959524\n",
      " 0.42413333 0.7372     0.13055714 0.64681053 0.08959524 0.16111304\n",
      " 0.12854    0.08605    0.5769     0.0032     0.68095    0.7372\n",
      " 0.7241     0.73929091 0.60236667 0.545075   0.439425   0.1175\n",
      " 0.69044    0.0032     0.60154906 0.0019     0.5835     0.70946667\n",
      " 0.71287838 0.12330455 0.78106667 0.0032     0.6908     0.110225\n",
      " 0.1175     0.73929091 0.60154906 0.51185    0.0041     0.0032\n",
      " 0.60154906 0.32005    0.7772     0.62396667 0.5082     0.12866667\n",
      " 0.64681053 0.60154906 0.27791429 0.56285    0.39584    0.5082\n",
      " 0.4955     0.00855    0.12854    0.6791     0.660975   0.68555\n",
      " 0.69044    0.734625   0.63409091 0.660975   0.00415    0.00615\n",
      " 0.08959524 0.002      0.0717087  0.1175     0.00415    0.52460385\n",
      " 0.70946667 0.70446923 0.09967778 0.71287838 0.00726667 0.668875\n",
      " 0.73929091 0.62396667 0.45482609 0.77570784 0.7027     0.00415\n",
      " 0.0029     0.78106667 0.5163     0.4584     0.0028     0.72032222\n",
      " 0.1175     0.12866667 0.0032     0.0032     0.5292     0.110225\n",
      " 0.70946667 0.71287838 0.45482609 0.70946667 0.13055714 0.53324286\n",
      " 0.52460385 0.76663333 0.77570784 0.6375     0.00195    0.8364\n",
      " 0.68535    0.70446923 0.0026     0.7508     0.77570784 0.56556667\n",
      " 0.28306    0.89484    0.63409091 0.8364     0.0717087  0.12866667\n",
      " 0.7372     0.64       0.52460385 0.0032     0.89484    0.639775\n",
      " 0.0032     0.00205    0.5769     0.12866667 0.7027     0.70446923\n",
      " 0.6789     0.71287838 0.692875   0.52460385 0.71287838 0.7226\n",
      " 0.00194    0.668875   0.64132    0.77570784 0.0032     0.12330455\n",
      " 0.6775     0.70446923 0.101912   0.70446923 0.0021     0.77570784\n",
      " 0.6747     0.439425   0.71287838 0.5769     0.68535    0.00625\n",
      " 0.08605    0.66882857 0.72913    0.545075   0.62396667 0.477\n",
      " 0.63409091 0.12330455 0.68242    0.101912   0.5769     0.00194\n",
      " 0.16111304 0.12330455 0.00205    0.08959524 0.668875   0.13055714\n",
      " 0.73929091 0.101912   0.72913    0.71287838 0.6468     0.482332\n",
      " 0.77570784 0.7372     0.54184    0.60236667 0.68555    0.45495714\n",
      " 0.00205    0.63409091 0.12854    0.6431     0.64681053 0.12330455\n",
      " 0.08605    0.00615    0.00625    0.12866667 0.52295    0.68095\n",
      " 0.70946667 0.0032     0.58882    0.88391    0.00934    0.73929091\n",
      " 0.13055714 0.8364     0.0717087  0.08605    0.58882    0.8364\n",
      " 0.110225   0.0034     0.4707     0.08605    0.08959524 0.77570784\n",
      " 0.0717087  0.09967778 0.51185    0.09967778 0.0026     0.12330455\n",
      " 0.63409091 0.0041     0.08605    0.45482609 0.6468     0.89484\n",
      " 0.00336667 0.60154906 0.4469     0.12866667 0.4469     0.56285\n",
      " 0.28306    0.110225   0.62396667 0.00348571 0.08605    0.6468\n",
      " 0.77570784 0.08959524 0.12330455 0.5835     0.0019     0.0026\n",
      " 0.0717087  0.00726667 0.08959524 0.77570784 0.73929091 0.6398\n",
      " 0.639      0.00415    0.668875   0.7372     0.6791     0.0041\n",
      " 0.7372     0.00415    0.68242    0.004      0.0026     0.660975\n",
      " 0.00336667 0.66882857 0.0034     0.64681053 0.16111304 0.6789\n",
      " 0.68555    0.1175     0.5769     0.51585    0.08605    0.08605\n",
      " 0.7372     0.54184    0.78106667 0.08605    0.6218     0.71287838\n",
      " 0.12854    0.2756     0.7508     0.12330455 0.67593333 0.60154906\n",
      " 0.60035    0.77570784 0.00582    0.110225   0.45482609 0.41344\n",
      " 0.482332   0.62396667 0.6775     0.7372     0.101912   0.110225\n",
      " 0.12866667 0.110225   0.52460385 0.1175     0.4517     0.7422375\n",
      " 0.64681053 0.6398     0.004      0.63409091 0.13055714 0.7508\n",
      " 0.00625    0.78106667 0.0026     0.73929091 0.00415    0.45482609\n",
      " 0.58882    0.71287838 0.51185    0.89484    0.57675    0.110225\n",
      " 0.0041     0.7774     0.0717087  0.8        0.71287838 0.51185\n",
      " 0.78515    0.734625   0.4584     0.12866667 0.60154906 0.0066\n",
      " 0.78106667 0.00934    0.71287838 0.62396667 0.2756     0.12330455\n",
      " 0.0021     0.110225   0.64681053 0.73929091 0.71287838 0.6468\n",
      " 0.0019     0.12854    0.0717087  0.0028     0.6775     0.62396667\n",
      " 0.660975   0.71287838 0.60154906 0.08959524 0.6468     0.6866\n",
      " 0.5584     0.6775     0.52295    0.63409091 0.69044    0.00205\n",
      " 0.4512     0.6908     0.6791     0.60154906 0.00582    0.52295\n",
      " 0.78515    0.6398     0.52695556 0.0066     0.70446923 0.477\n",
      " 0.6468     0.2875     0.6468     0.45482609 0.5584     0.73929091\n",
      " 0.439425   0.08959524 0.64681053 0.12854    0.482332   0.12866667\n",
      " 0.64132    0.0026     0.08605    0.45482609 0.57675    0.13055714\n",
      " 0.52295    0.12330455 0.0069     0.0032     0.1175     0.00582\n",
      " 0.00625    0.4955     0.2875     0.37256667 0.692875   0.56556667\n",
      " 0.62396667 0.1175     0.7372     0.110225   0.6031     0.66882857\n",
      " 0.0019     0.64132    0.7372     0.7383     0.6747     0.439425\n",
      " 0.52695556 0.08605    0.68242    0.77570784 0.00193333 0.00195\n",
      " 0.13055714 0.64681053 0.8364     0.54184    0.6431     0.0032\n",
      " 0.70446923 0.6789     0.28306    0.68555    0.12854    0.12854\n",
      " 0.60154906 0.62396667 0.09967778 0.77570784 0.101912   0.9009\n",
      " 0.37256667 0.70946667 0.8364     0.6431     0.08605    0.110225\n",
      " 0.45495714 0.09967778 0.45482609 0.00205    0.5163     0.71287838\n",
      " 0.12854    0.0026     0.63409091 0.6218     0.6398     0.08605\n",
      " 0.2756     0.64681053 0.64681053 0.52695556 0.0034     0.101912\n",
      " 0.00855    0.51585    0.5163     0.00194    0.89484    0.66882857\n",
      " 0.73929091 0.00855    0.68535    0.6908     0.7372     0.6789\n",
      " 0.70946667 0.6468     0.60154906 0.70946667 0.08605    0.00193333\n",
      " 0.5584     0.08959524 0.482332   0.668875   0.6775     0.482332\n",
      " 0.13055714 0.6949     0.0026     0.12866667 0.13055714 0.482332\n",
      " 0.60154906 0.39584   ]\n"
     ]
    }
   ],
   "source": [
    "##Predict new value\n",
    "y_pred_DTR = DecTree_reg.predict(X_test)   #predicting new precision values using X_test\n",
    "print(y_pred_DTR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65e5a034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean squared error: 0.11\n",
      "Mean absolute error: 0.07\n"
     ]
    }
   ],
   "source": [
    "##Evaluation of new prediction and model accuracy\n",
    "print(\"Root Mean squared error: %.2f\" % math.sqrt(metrics.mean_squared_error(Y_test, y_pred_DTR)))\n",
    "print(\"Mean absolute error: %.2f\" % metrics.mean_absolute_error(Y_test, y_pred_DTR))\n",
    "#print(\"Accuracy: %.2f\" % metrics.r2_score(Y_test,y_pred_DTR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0721725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f20743f8",
   "metadata": {},
   "source": [
    "### Random Forest Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa9a76e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(min_samples_leaf=5, n_estimators=50)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Calling the random forest regression model\n",
    "RanFor_reg = RandomForestRegressor(n_estimators = 50, min_samples_leaf=5) #model without random state gives different result(higher accuracy??)\n",
    "#RanFor_reg = RandomForestRegressor(n_estimators = 50, min_samples_leaf=5, random_state = 24)\n",
    "##Fitting the model with dataset\n",
    "RanFor_reg.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d29f7414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77570231 0.52182891 0.87860225 0.57130641 0.66948924 0.74016269\n",
      " 0.63525555 0.71355263 0.45324224 0.59825265 0.50465963 0.49299223\n",
      " 0.68233348 0.68430935 0.49281651 0.16171141 0.6509816  0.39002923\n",
      " 0.6430262  0.16171141 0.71355263 0.67538949 0.70421053 0.13786929\n",
      " 0.68850298 0.70350587 0.6509816  0.00726181 0.68850298 0.62132973\n",
      " 0.3168851  0.4160779  0.73658359 0.13924545 0.11831014 0.66731574\n",
      " 0.7468093  0.63525555 0.74567141 0.6430262  0.59825265 0.3168851\n",
      " 0.09717727 0.7611893  0.13837293 0.00409542 0.09896816 0.70283759\n",
      " 0.08924886 0.62690697 0.16171141 0.72204097 0.58603553 0.11738835\n",
      " 0.11831014 0.52182891 0.13837293 0.34102201 0.67538949 0.00378447\n",
      " 0.48157793 0.71355263 0.64875192 0.70350587 0.06665497 0.08924886\n",
      " 0.00669749 0.16171141 0.62690697 0.64875192 0.00226149 0.6430262\n",
      " 0.70116692 0.16171141 0.71355263 0.13924545 0.16171141 0.48365295\n",
      " 0.01941098 0.52654659 0.64875192 0.0210156  0.08924886 0.00205405\n",
      " 0.72204097 0.49281651 0.69188715 0.11831014 0.06665497 0.58447545\n",
      " 0.13924545 0.85916002 0.63253016 0.71355263 0.69534053 0.09896816\n",
      " 0.49494055 0.73658359 0.13837293 0.64875192 0.09896816 0.16171141\n",
      " 0.13924545 0.08924886 0.48365295 0.00395402 0.66903183 0.73658359\n",
      " 0.72848428 0.73960582 0.60134409 0.56919852 0.42427934 0.11831014\n",
      " 0.67904503 0.00395402 0.59825265 0.04067524 0.58868558 0.69417327\n",
      " 0.71355263 0.12463706 0.73847547 0.00378447 0.68850298 0.11738835\n",
      " 0.11831014 0.73960582 0.59825265 0.36761689 0.00356684 0.00395402\n",
      " 0.59825265 0.34102201 0.70309402 0.62690697 0.51650516 0.13786929\n",
      " 0.64875192 0.59825265 0.32278798 0.59338678 0.4160779  0.51650516\n",
      " 0.49281651 0.0210156  0.13924545 0.6509816  0.66328761 0.69658941\n",
      " 0.67904503 0.72204097 0.63525555 0.66328761 0.00316046 0.0049288\n",
      " 0.09896816 0.00205405 0.06665497 0.11831014 0.00755111 0.52654659\n",
      " 0.69417327 0.70421053 0.10208745 0.71355263 0.00720778 0.66686466\n",
      " 0.73960582 0.62690697 0.45324224 0.77570231 0.6923653  0.00316046\n",
      " 0.00409542 0.73847547 0.50653789 0.46262879 0.00295235 0.72254412\n",
      " 0.11831014 0.13786929 0.00447381 0.00395402 0.49299223 0.11738835\n",
      " 0.69417327 0.71355263 0.45324224 0.69417327 0.13837293 0.53560362\n",
      " 0.52654659 0.74016269 0.77570231 0.68233348 0.00227504 0.790641\n",
      " 0.69534053 0.70421053 0.00437146 0.7468093  0.77570231 0.51939213\n",
      " 0.36470697 0.85002738 0.63525555 0.790641   0.06665497 0.13786929\n",
      " 0.74480035 0.71972469 0.52654659 0.00447381 0.85002738 0.63487106\n",
      " 0.01808852 0.00226149 0.48365295 0.13786929 0.69188715 0.70421053\n",
      " 0.69182788 0.71355263 0.70350587 0.52654659 0.71355263 0.73372969\n",
      " 0.00232787 0.66686466 0.64049953 0.77570231 0.00447381 0.12463706\n",
      " 0.68430935 0.70421053 0.09717727 0.70421053 0.00238505 0.77570231\n",
      " 0.69972359 0.42427934 0.71355263 0.48365295 0.69534053 0.00471166\n",
      " 0.08924886 0.67578013 0.73833729 0.56919852 0.62690697 0.45325961\n",
      " 0.63525555 0.12463706 0.69309918 0.09717727 0.48365295 0.00232787\n",
      " 0.16171141 0.12463706 0.00226149 0.09896816 0.66686466 0.13837293\n",
      " 0.73960582 0.09717727 0.73833729 0.71355263 0.6430262  0.48157793\n",
      " 0.77570231 0.73658359 0.58844048 0.60134409 0.69658941 0.47233175\n",
      " 0.05224746 0.63525555 0.13924545 0.64310718 0.64875192 0.12463706\n",
      " 0.08924886 0.0049288  0.00471166 0.13786929 0.50076526 0.66903183\n",
      " 0.69417327 0.01808852 0.60284889 0.87860225 0.00726181 0.73960582\n",
      " 0.13837293 0.790641   0.06665497 0.08924886 0.60284889 0.790641\n",
      " 0.11738835 0.00349283 0.46949378 0.08924886 0.09896816 0.77570231\n",
      " 0.06665497 0.10208745 0.36761689 0.10208745 0.01773617 0.12463706\n",
      " 0.63525555 0.00356684 0.08924886 0.45324224 0.6430262  0.85002738\n",
      " 0.03699512 0.59825265 0.42396061 0.13786929 0.42396061 0.59338678\n",
      " 0.36470697 0.11738835 0.62690697 0.006036   0.08924886 0.6430262\n",
      " 0.77570231 0.09896816 0.12463706 0.58868558 0.04067524 0.01773617\n",
      " 0.06665497 0.00720778 0.09896816 0.77570231 0.73960582 0.63253016\n",
      " 0.61009119 0.00316046 0.66686466 0.73658359 0.6509816  0.00356684\n",
      " 0.73658359 0.00755111 0.69309918 0.00669749 0.00288143 0.66328761\n",
      " 0.03699512 0.67958953 0.00349283 0.64875192 0.16171141 0.68958065\n",
      " 0.69658941 0.11831014 0.48365295 0.50932423 0.08924886 0.08924886\n",
      " 0.73658359 0.58844048 0.73847547 0.08924886 0.60894126 0.71355263\n",
      " 0.13924545 0.39002923 0.7468093  0.12463706 0.66948924 0.59825265\n",
      " 0.58603553 0.77570231 0.01104437 0.11738835 0.45324224 0.3168851\n",
      " 0.48157793 0.62690697 0.68430935 0.73658359 0.09717727 0.11738835\n",
      " 0.13786929 0.11738835 0.52654659 0.11831014 0.52976418 0.74897733\n",
      " 0.64875192 0.63253016 0.00669749 0.63525555 0.13837293 0.7468093\n",
      " 0.00471166 0.73847547 0.00288143 0.73960582 0.00316046 0.45324224\n",
      " 0.60284889 0.71355263 0.36761689 0.85002738 0.55711255 0.11738835\n",
      " 0.00356684 0.75151027 0.06665497 0.74567141 0.71355263 0.36761689\n",
      " 0.79004879 0.72204097 0.46262879 0.13786929 0.59825265 0.00557749\n",
      " 0.73847547 0.00726181 0.71355263 0.62690697 0.39002923 0.12463706\n",
      " 0.00238505 0.11738835 0.64875192 0.73960582 0.71355263 0.6430262\n",
      " 0.04067524 0.13924545 0.06665497 0.01721821 0.68402063 0.62690697\n",
      " 0.66328761 0.71355263 0.59825265 0.09896816 0.6430262  0.70116692\n",
      " 0.58447545 0.68430935 0.50076526 0.63525555 0.67904503 0.05224746\n",
      " 0.61484977 0.68850298 0.6509816  0.59825265 0.01104437 0.50076526\n",
      " 0.79004879 0.63253016 0.52182891 0.00557749 0.70421053 0.45325961\n",
      " 0.6430262  0.23809325 0.6430262  0.45324224 0.58447545 0.73960582\n",
      " 0.42427934 0.09896816 0.64875192 0.13924545 0.48157793 0.13786929\n",
      " 0.64049953 0.00437146 0.08924886 0.45324224 0.55711255 0.13837293\n",
      " 0.50076526 0.12463706 0.00551574 0.00447381 0.11831014 0.01104437\n",
      " 0.00471166 0.49281651 0.23809325 0.34905742 0.70350587 0.51939213\n",
      " 0.62690697 0.11831014 0.73658359 0.11738835 0.584638   0.67958953\n",
      " 0.04067524 0.64049953 0.74480035 0.66563828 0.70089584 0.42427934\n",
      " 0.52182891 0.08924886 0.69309918 0.77570231 0.00204984 0.00227504\n",
      " 0.13837293 0.64875192 0.790641   0.58844048 0.64310718 0.00378447\n",
      " 0.70421053 0.68958065 0.36470697 0.69658941 0.13924545 0.13924545\n",
      " 0.59825265 0.62690697 0.10208745 0.77570231 0.09717727 0.71048856\n",
      " 0.34905742 0.69417327 0.790641   0.64310718 0.08924886 0.11738835\n",
      " 0.47233175 0.10208745 0.45324224 0.00226149 0.50653789 0.71355263\n",
      " 0.13924545 0.00437146 0.63525555 0.60894126 0.63253016 0.08924886\n",
      " 0.39002923 0.64875192 0.64875192 0.52182891 0.01941098 0.09717727\n",
      " 0.0210156  0.50932423 0.50653789 0.00232787 0.85002738 0.67578013\n",
      " 0.73960582 0.0210156  0.69534053 0.68850298 0.74480035 0.69182788\n",
      " 0.69417327 0.6430262  0.59825265 0.69417327 0.08924886 0.00204984\n",
      " 0.58447545 0.09896816 0.48157793 0.66686466 0.68402063 0.48157793\n",
      " 0.13837293 0.66212216 0.01773617 0.13786929 0.13837293 0.48157793\n",
      " 0.59825265 0.4160779 ]\n"
     ]
    }
   ],
   "source": [
    "##Predict new precision values\n",
    "y_pred_RFR = RanFor_reg.predict(X_test)\n",
    "print(y_pred_RFR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "682c6dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean squared error: 0.12\n",
      "Mean absolute error: 0.07\n"
     ]
    }
   ],
   "source": [
    "#evaluting RandForest_reg and model accuracy\n",
    "print(\"Root Mean squared error: %.2f\" % math.sqrt(metrics.mean_squared_error(Y_test, y_pred_RFR)))\n",
    "print(\"Mean absolute error: %.2f\" % metrics.mean_absolute_error(Y_test, y_pred_RFR))\n",
    "#print(\"Accuracy: %.2f\" % metrics.r2_score(Y_test,y_pred_RFR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5705b70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c00870a2",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM) Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be8a5709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the SVM model over the training data\n",
    "from sklearn.svm import SVR           #Support vector regressor model\n",
    "SuppVec_reg = SVR(kernel = 'rbf')\n",
    "SuppVec_reg.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0912756f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77570231 0.52182891 0.87860225 0.57130641 0.66948924 0.74016269\n",
      " 0.63525555 0.71355263 0.45324224 0.59825265 0.50465963 0.49299223\n",
      " 0.68233348 0.68430935 0.49281651 0.16171141 0.6509816  0.39002923\n",
      " 0.6430262  0.16171141 0.71355263 0.67538949 0.70421053 0.13786929\n",
      " 0.68850298 0.70350587 0.6509816  0.00726181 0.68850298 0.62132973\n",
      " 0.3168851  0.4160779  0.73658359 0.13924545 0.11831014 0.66731574\n",
      " 0.7468093  0.63525555 0.74567141 0.6430262  0.59825265 0.3168851\n",
      " 0.09717727 0.7611893  0.13837293 0.00409542 0.09896816 0.70283759\n",
      " 0.08924886 0.62690697 0.16171141 0.72204097 0.58603553 0.11738835\n",
      " 0.11831014 0.52182891 0.13837293 0.34102201 0.67538949 0.00378447\n",
      " 0.48157793 0.71355263 0.64875192 0.70350587 0.06665497 0.08924886\n",
      " 0.00669749 0.16171141 0.62690697 0.64875192 0.00226149 0.6430262\n",
      " 0.70116692 0.16171141 0.71355263 0.13924545 0.16171141 0.48365295\n",
      " 0.01941098 0.52654659 0.64875192 0.0210156  0.08924886 0.00205405\n",
      " 0.72204097 0.49281651 0.69188715 0.11831014 0.06665497 0.58447545\n",
      " 0.13924545 0.85916002 0.63253016 0.71355263 0.69534053 0.09896816\n",
      " 0.49494055 0.73658359 0.13837293 0.64875192 0.09896816 0.16171141\n",
      " 0.13924545 0.08924886 0.48365295 0.00395402 0.66903183 0.73658359\n",
      " 0.72848428 0.73960582 0.60134409 0.56919852 0.42427934 0.11831014\n",
      " 0.67904503 0.00395402 0.59825265 0.04067524 0.58868558 0.69417327\n",
      " 0.71355263 0.12463706 0.73847547 0.00378447 0.68850298 0.11738835\n",
      " 0.11831014 0.73960582 0.59825265 0.36761689 0.00356684 0.00395402\n",
      " 0.59825265 0.34102201 0.70309402 0.62690697 0.51650516 0.13786929\n",
      " 0.64875192 0.59825265 0.32278798 0.59338678 0.4160779  0.51650516\n",
      " 0.49281651 0.0210156  0.13924545 0.6509816  0.66328761 0.69658941\n",
      " 0.67904503 0.72204097 0.63525555 0.66328761 0.00316046 0.0049288\n",
      " 0.09896816 0.00205405 0.06665497 0.11831014 0.00755111 0.52654659\n",
      " 0.69417327 0.70421053 0.10208745 0.71355263 0.00720778 0.66686466\n",
      " 0.73960582 0.62690697 0.45324224 0.77570231 0.6923653  0.00316046\n",
      " 0.00409542 0.73847547 0.50653789 0.46262879 0.00295235 0.72254412\n",
      " 0.11831014 0.13786929 0.00447381 0.00395402 0.49299223 0.11738835\n",
      " 0.69417327 0.71355263 0.45324224 0.69417327 0.13837293 0.53560362\n",
      " 0.52654659 0.74016269 0.77570231 0.68233348 0.00227504 0.790641\n",
      " 0.69534053 0.70421053 0.00437146 0.7468093  0.77570231 0.51939213\n",
      " 0.36470697 0.85002738 0.63525555 0.790641   0.06665497 0.13786929\n",
      " 0.74480035 0.71972469 0.52654659 0.00447381 0.85002738 0.63487106\n",
      " 0.01808852 0.00226149 0.48365295 0.13786929 0.69188715 0.70421053\n",
      " 0.69182788 0.71355263 0.70350587 0.52654659 0.71355263 0.73372969\n",
      " 0.00232787 0.66686466 0.64049953 0.77570231 0.00447381 0.12463706\n",
      " 0.68430935 0.70421053 0.09717727 0.70421053 0.00238505 0.77570231\n",
      " 0.69972359 0.42427934 0.71355263 0.48365295 0.69534053 0.00471166\n",
      " 0.08924886 0.67578013 0.73833729 0.56919852 0.62690697 0.45325961\n",
      " 0.63525555 0.12463706 0.69309918 0.09717727 0.48365295 0.00232787\n",
      " 0.16171141 0.12463706 0.00226149 0.09896816 0.66686466 0.13837293\n",
      " 0.73960582 0.09717727 0.73833729 0.71355263 0.6430262  0.48157793\n",
      " 0.77570231 0.73658359 0.58844048 0.60134409 0.69658941 0.47233175\n",
      " 0.05224746 0.63525555 0.13924545 0.64310718 0.64875192 0.12463706\n",
      " 0.08924886 0.0049288  0.00471166 0.13786929 0.50076526 0.66903183\n",
      " 0.69417327 0.01808852 0.60284889 0.87860225 0.00726181 0.73960582\n",
      " 0.13837293 0.790641   0.06665497 0.08924886 0.60284889 0.790641\n",
      " 0.11738835 0.00349283 0.46949378 0.08924886 0.09896816 0.77570231\n",
      " 0.06665497 0.10208745 0.36761689 0.10208745 0.01773617 0.12463706\n",
      " 0.63525555 0.00356684 0.08924886 0.45324224 0.6430262  0.85002738\n",
      " 0.03699512 0.59825265 0.42396061 0.13786929 0.42396061 0.59338678\n",
      " 0.36470697 0.11738835 0.62690697 0.006036   0.08924886 0.6430262\n",
      " 0.77570231 0.09896816 0.12463706 0.58868558 0.04067524 0.01773617\n",
      " 0.06665497 0.00720778 0.09896816 0.77570231 0.73960582 0.63253016\n",
      " 0.61009119 0.00316046 0.66686466 0.73658359 0.6509816  0.00356684\n",
      " 0.73658359 0.00755111 0.69309918 0.00669749 0.00288143 0.66328761\n",
      " 0.03699512 0.67958953 0.00349283 0.64875192 0.16171141 0.68958065\n",
      " 0.69658941 0.11831014 0.48365295 0.50932423 0.08924886 0.08924886\n",
      " 0.73658359 0.58844048 0.73847547 0.08924886 0.60894126 0.71355263\n",
      " 0.13924545 0.39002923 0.7468093  0.12463706 0.66948924 0.59825265\n",
      " 0.58603553 0.77570231 0.01104437 0.11738835 0.45324224 0.3168851\n",
      " 0.48157793 0.62690697 0.68430935 0.73658359 0.09717727 0.11738835\n",
      " 0.13786929 0.11738835 0.52654659 0.11831014 0.52976418 0.74897733\n",
      " 0.64875192 0.63253016 0.00669749 0.63525555 0.13837293 0.7468093\n",
      " 0.00471166 0.73847547 0.00288143 0.73960582 0.00316046 0.45324224\n",
      " 0.60284889 0.71355263 0.36761689 0.85002738 0.55711255 0.11738835\n",
      " 0.00356684 0.75151027 0.06665497 0.74567141 0.71355263 0.36761689\n",
      " 0.79004879 0.72204097 0.46262879 0.13786929 0.59825265 0.00557749\n",
      " 0.73847547 0.00726181 0.71355263 0.62690697 0.39002923 0.12463706\n",
      " 0.00238505 0.11738835 0.64875192 0.73960582 0.71355263 0.6430262\n",
      " 0.04067524 0.13924545 0.06665497 0.01721821 0.68402063 0.62690697\n",
      " 0.66328761 0.71355263 0.59825265 0.09896816 0.6430262  0.70116692\n",
      " 0.58447545 0.68430935 0.50076526 0.63525555 0.67904503 0.05224746\n",
      " 0.61484977 0.68850298 0.6509816  0.59825265 0.01104437 0.50076526\n",
      " 0.79004879 0.63253016 0.52182891 0.00557749 0.70421053 0.45325961\n",
      " 0.6430262  0.23809325 0.6430262  0.45324224 0.58447545 0.73960582\n",
      " 0.42427934 0.09896816 0.64875192 0.13924545 0.48157793 0.13786929\n",
      " 0.64049953 0.00437146 0.08924886 0.45324224 0.55711255 0.13837293\n",
      " 0.50076526 0.12463706 0.00551574 0.00447381 0.11831014 0.01104437\n",
      " 0.00471166 0.49281651 0.23809325 0.34905742 0.70350587 0.51939213\n",
      " 0.62690697 0.11831014 0.73658359 0.11738835 0.584638   0.67958953\n",
      " 0.04067524 0.64049953 0.74480035 0.66563828 0.70089584 0.42427934\n",
      " 0.52182891 0.08924886 0.69309918 0.77570231 0.00204984 0.00227504\n",
      " 0.13837293 0.64875192 0.790641   0.58844048 0.64310718 0.00378447\n",
      " 0.70421053 0.68958065 0.36470697 0.69658941 0.13924545 0.13924545\n",
      " 0.59825265 0.62690697 0.10208745 0.77570231 0.09717727 0.71048856\n",
      " 0.34905742 0.69417327 0.790641   0.64310718 0.08924886 0.11738835\n",
      " 0.47233175 0.10208745 0.45324224 0.00226149 0.50653789 0.71355263\n",
      " 0.13924545 0.00437146 0.63525555 0.60894126 0.63253016 0.08924886\n",
      " 0.39002923 0.64875192 0.64875192 0.52182891 0.01941098 0.09717727\n",
      " 0.0210156  0.50932423 0.50653789 0.00232787 0.85002738 0.67578013\n",
      " 0.73960582 0.0210156  0.69534053 0.68850298 0.74480035 0.69182788\n",
      " 0.69417327 0.6430262  0.59825265 0.69417327 0.08924886 0.00204984\n",
      " 0.58447545 0.09896816 0.48157793 0.66686466 0.68402063 0.48157793\n",
      " 0.13837293 0.66212216 0.01773617 0.13786929 0.13837293 0.48157793\n",
      " 0.59825265 0.4160779 ]\n"
     ]
    }
   ],
   "source": [
    "##Predict new precision values\n",
    "y_pred_SVR = SuppVec_reg.predict(X_test)\n",
    "print(y_pred_RFR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6005752d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean squared error: 0.23\n",
      "Mean absolute error: 0.16\n"
     ]
    }
   ],
   "source": [
    "#evaluting RandForest_reg and model accuracy\n",
    "print(\"Root Mean squared error: %.2f\" % math.sqrt(metrics.mean_squared_error(Y_test, y_pred_SVR)))\n",
    "print(\"Mean absolute error: %.2f\" % metrics.mean_absolute_error(Y_test, y_pred_SVR))\n",
    "#print(\"Accuracy: %.2f\" % metrics.r2_score(Y_test,y_pred_SVR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1d5e76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b261231d",
   "metadata": {},
   "source": [
    "### Comparing Different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e49e81f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Error: [0.11, 0.12, 0.23]\n"
     ]
    }
   ],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "names = ['DecTree Reg','RandFor Reg','SuppVec Reg']\n",
    "predictions=[y_pred_DTR,y_pred_RFR,y_pred_SVR]\n",
    "results = []\n",
    "\n",
    "for y_pred in predictions:\n",
    "  rmse=round(math.sqrt(metrics.mean_squared_error(Y_test, y_pred)),2)\n",
    "  #mae=round(metrics.mean_absolute_error(Y_test, y_pred),2)\n",
    "  results.append(rmse) #change rmse to mae \n",
    "  \n",
    "# create a bar plot to compare values\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Model RMSE Comparison: ')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.bar(names,results)\n",
    "plt.show()\n",
    "\n",
    "print (\"Model Error:\",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282d48de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44258032",
   "metadata": {},
   "source": [
    "### END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967b74e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
